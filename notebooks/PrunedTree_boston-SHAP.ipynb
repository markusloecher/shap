{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning sklearn DecisionTreeClassifiers\n",
    "\n",
    "This post serves two purposes:\n",
    "1. It shows a simple quick way of manually pruning selected nodes from the tree.\n",
    "2. It points out ensuing problems in computing SHAP values\n",
    "\n",
    "It seems that we need a more comprehensive post pruning function for trees, an issue which I have (unsuccessfully) raised here:\n",
    "\n",
    "https://github.com/scikit-learn/scikit-learn/issues/18680#issuecomment-716163291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "#for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "import shap\n",
    "X,y = shap.datasets.boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth=3\n",
    "tree_B1 = tree.DecisionTreeRegressor(random_state=0,max_depth=max_depth)\n",
    "tree_B1 = tree_B1.fit(X.values, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now selectively prune the two left and the one right extreme parent nodes 2,5 and 12 (in layer depth2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_B2 = copy.deepcopy(tree_B1)\n",
    "#prune the tree\n",
    "for i in [2,5,12]:\n",
    "    tree_B2.tree_.children_left[i] = -1\n",
    "    tree_B2.tree_.children_right[i]  = -1\n",
    "    tree_B2.tree_.n_node_samples[i] = 0\n",
    "    tree_B2.tree_.weighted_n_node_samples[i]  = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the trees side by side\n",
    "![Original versus pruned tree](figures/BothTrees.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pruning procedure from above did not actually remove the nodes from the tree data structure but simply terminated the links. \n",
    "It is not clear to me which functions and/or modules access the nodes\n",
    "\n",
    "* via tree traversal -- in which case they would \"see\" a pruned tree, opposed to \n",
    "* directly as an array, -- in which case the \"shallow\" pruning would not have an effect\n",
    "\n",
    "In the following we investigate the effect of pruning on SHAP values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting feature_perturbation = \"tree_path_dependent\" because no background data was given.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The background dataset you provided does not cover all the leaves in the model, so TreeExplainer cannot run with the feature_perturbation=\"tree_path_dependent\" option! Try providing a larger background dataset, or using feature_perturbation=\"interventional\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-ffe1cf1826fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mexplainer2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_B2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mShap_train2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\shap\\explainers\\tree.py\u001b[0m in \u001b[0;36mshap_values\u001b[1;34m(self, X, y, tree_limit, approximate, check_additivity)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_perturbation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tree_path_dependent\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfully_defined_weighting\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"The background dataset you provided does not cover all the leaves in the model, \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m                                                        \u001b[1;34m\"so TreeExplainer cannot run with the feature_perturbation=\\\"tree_path_dependent\\\" option! \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                                                        \u001b[1;34m\"Try providing a larger background dataset, or using feature_perturbation=\\\"interventional\\\".\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: The background dataset you provided does not cover all the leaves in the model, so TreeExplainer cannot run with the feature_perturbation=\"tree_path_dependent\" option! Try providing a larger background dataset, or using feature_perturbation=\"interventional\"."
     ]
    }
   ],
   "source": [
    "explainer1 = shap.TreeExplainer(tree_B1)\n",
    "Shap_train1 = explainer1.shap_values(X)\n",
    "\n",
    "explainer2 = shap.TreeExplainer(tree_B2)\n",
    "Shap_train2 = explainer2.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(Shap_train1, X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(Shap_train2, X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we deliberately changed the values of the pruned nodes ? Does that affect the SHAP vales ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The node IDs of the pruned leafs are:  3,4,6,7,13,14\n",
    "np.random.seed(123)\n",
    "tree_B2.tree_.value[[3,4,6,7,13,14]]  = np.reshape(np.random.normal(0,20,6), (6,1,1))\n",
    "for i in np.arange(tree_B2.tree_.node_count):\n",
    "    tree_B2.tree_.n_node_samples[i] = 0.5*tree_B2.tree_.n_node_samples[i] #?\n",
    "    tree_B2.tree_.weighted_n_node_samples[i] = 0.5*tree_B2.tree_.weighted_n_node_samples[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer2b = shap.TreeExplainer(tree_B2)\n",
    "Shap_train2b = explainer2b.shap_values(X)\n",
    "shap.summary_plot(Shap_train2b, X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
