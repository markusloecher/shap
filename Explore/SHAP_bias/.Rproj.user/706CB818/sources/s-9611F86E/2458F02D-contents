---
title: "SHAP_TitanicRegV3_QW.Rmd"
author: "Wu Qi"
date: "12/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate) #qi: note: need to reload python packages into miniconda,e.g. py_install("pandas")
rerun = TRUE  # If set to FALSE, the file "shap_inbag_oob.rda" is read in instead
if (!rerun) load("shap_inbag_oob.rda")
WIDTH = 5
HEIGHT = 5
```

```{python}
import pandas as pd
import numpy as np
np.random.seed(0)
import matplotlib.pyplot as plt
import shap
import pickle

from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.ensemble import RandomForestRegressor

rerun = r.rerun # qi: note: define python variable from known r variable
```
## Setting up the data 
```{python, eval = rerun}
df = pd.read_csv('../titanicnoMissingAge.csv') # Load the data
Y = df['Survived']
X =  df[['Age', 'Pclass','Sex', 'PassengerId']]
# Split the data into train and test data:
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2) 
# qi: reamrk: actually there's no need to separate train and test in this case? since the oob data is taken from the train set? unless we want to validate the model with test set at the end.
```
## Defining our python functions
```{python}
def plotImp(importances,features, 
            main = 'Feature Importances',xlab='Relative Importance'):
    indices = np.argsort(importances)
    #features = X_train.columns
    plt.title(main)
    plt.barh(range(len(indices)), importances[indices], color='b', align='center')
    plt.yticks(range(len(indices)), [features[i] for i in indices])
    plt.xlabel(xlab)
    plt.show()
    
def oob_regression_r2_score(rf, X_train, y_train):
    """
    Compute out-of-bag (OOB) R^2 for a scikit-learn random forest
    regressor. We learned the guts of scikit's RF from the BSD licensed
    code:
    https://github.com/scikit-learn/scikit-learn/blob/a24c8b46/sklearn/ensemble/forest.py#L702
    """
    X = X_train.values if isinstance(X_train, pd.DataFrame) else X_train
    y = y_train.values if isinstance(y_train, pd.Series) else y_train

    n_samples = len(X)
    predictions = np.zeros(n_samples)
    n_predictions = np.zeros(n_samples)
    for tree in rf.estimators_:
        unsampled_indices = generate_unsampled_indices(tree.random_state, n_samples)
        tree_preds = tree.predict(X[unsampled_indices, :])
        predictions[unsampled_indices] += tree_preds # qi: note: add up the predicted value, will be devided later by the nr 
        n_predictions[unsampled_indices] += 1 # qi: note: how many times some indices were not sampled 

    if (n_predictions == 0).any():
        warnings.warn("Too few trees; some variables do not have OOB scores.")
        n_predictions[n_predictions == 0] = 1

    predictions /= n_predictions

    oob_score = r2_score(y, predictions)
    return oob_score

#http://bakfu.github.io/doc/_modules/sklearn/ensemble/forest.html
from sklearn.utils import check_random_state #, check_array, compute_sample_weight
#from sklearn.utils.fixes import bincount

def generate_sample_indices(random_state, n_samples):
    """Private function used to _parallel_build_trees function."""
    random_instance = check_random_state(random_state)
    sample_indices = random_instance.randint(0, n_samples, n_samples)

    return sample_indices

def generate_unsampled_indices(random_state, n_samples):
    """Private function used to forest._set_oob_score fuction."""
    sample_indices = generate_sample_indices(random_state, n_samples)
    sample_counts = np.bincount(sample_indices, minlength=n_samples)
    unsampled_mask = sample_counts == 0
    indices_range = np.arange(n_samples)
    unsampled_indices = indices_range[unsampled_mask]

    return unsampled_indices
```

## Fitting a random forest regressor

```{python}
from sklearn.ensemble import RandomForestRegressor 
rf = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=400,max_features=2)
rf.fit(X_train, Y_train)  
print(rf.feature_importances_)
importances = rf.feature_importances_
features = X_train.columns

plotImp(importances,features)
```

## Computing shap separately for inbag and oob:

```{python}
n_samples, p = X_train.shape

if (rerun):
    explainer_rf = shap.TreeExplainer(rf)
    shapGlobal = explainer_rf.shap_values(X_train)

    shap_oob = np.zeros((n_samples,p, rf.n_estimators))
    shap_inbag = np.zeros((n_samples,p, rf.n_estimators))
    for k,tree in enumerate(rf.estimators_):
      tree_preds = tree.predict(X_train) # qi: question: what is this variable's use?
      unsampled_indices = generate_unsampled_indices(tree.random_state, n_samples)
      sampled_indices = generate_sample_indices(tree.random_state, n_samples)
      explainer = shap.TreeExplainer(tree)
      shap_oob[unsampled_indices,:,k] = explainer.shap_values(X_train.iloc[unsampled_indices,:]) 
      shap_inbag[sampled_indices,:,k] = explainer.shap_values(X_train.iloc[sampled_indices,:])

print('unsampled indices shape in last tree of rf:',unsampled_indices.shape)

```

```{python}
shap_oob_avg = np.mean(shap_oob, axis=2) # qi: remark: take sum would do the same work
shap_inbag_avg = np.mean(shap_inbag, axis=2)

print(shap_oob_avg.shape)
print(shap_inbag_avg.shape)

globalSHAPImp_oob =np.sum(np.abs(shap_oob_avg), axis=0)
globalSHAPImp_inbag = np.sum(np.abs(shap_inbag_avg), axis=0)

shap_test = explainer_rf.shap_values(X_test)# qi: note: the test data take the explainer of rf 
print(shap_test.shape)
```

### Copying python objects into R 

```{r, eval = rerun}
shap_inbag_avg =py$shap_inbag_avg 
shap_oob_avg =py$shap_oob_avg 
colnames(shap_inbag_avg) = colnames(shap_oob_avg) = c('Age', 'Pclass','Sex', 'PassengerId')
shap_test = py$shap_test

Y_train = py$Y_train
X_train = py$X_train
X_test = py$X_test
Y_test = py$Y_test
# qi: remark: careful with overwritting
# save(shap_inbag_avg, shap_oob_avg, shap_test, X_train, X_test, Y_train, Y_test, file = "shap_inbag_oob.rda")
```

# R code only

```{r}
shap_inbag_avg_means = colMeans(abs(shap_inbag_avg))# qi: note: same as np.mean(shap_inbag_avg,axis=0)
shap_oob_avg_means = colMeans(abs(shap_oob_avg))
# set figure size global variable
WIDTH = 5
HEIGHT = 5
```

## "Raw" SHAP values
qi: remark: the size of plots in RStudio differ from html output

```{r, fig.width=WIDTH*2,fig.height=HEIGHT}

par(mfrow=c(2,2))
boxplot(shap_inbag_avg,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Inbag SHAP");grid()
barplot(shap_inbag_avg_means,col="bisque",main = "Inbag SHAP")
boxplot(shap_oob_avg,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob_avg_means,col="bisque",main = "OOB SHAP")
# means = colMeans(mdiScore2[[4]]);points(means,col="red",pch=18)

```

## Replace Node value with oob, prune tree and repace gini impurity(MSE in Regression case)
### Define prune function for decision tree 

### Run for each tree in Random forest 
```{python}
import copy 
def ReplaceRegTreeNodeValues(tree_orig, X_test, y_test, verbose =0):
    tree = copy.deepcopy(tree_orig)
    node_indicatorM = tree.decision_path(X_test).toarray()
    
    # matrix with nrows = nrow(X_test), ncol = num of nodes
    nm = node_indicatorM.shape 
    for j in np.arange(nm[1]): 
        y_test_node = y_test[node_indicatorM[:,j]==1]
        if np.isnan(np.mean(y_test_node)):
            tree.tree_.value[j] = 0
        else:
            tree.tree_.value[j] = np.mean(y_test_node)
        tree.tree_.n_node_samples[j] = len(y_test_node) 
#         tree.tree_.weighted_n_node_samples[j] = len(y_test_node)
    
    for j in np.arange(nm[1]): 
        # case1: children exist 
        if ((tree.tree_.children_left[j] != -1) & (tree.tree_.children_right[j] != -1)):
            index_cl = tree.tree_.children_left[j]
            index_cr = tree.tree_.children_right[j]
        
            y_test_nodel = y_test[node_indicatorM[:,index_cl]==1]
            y_test_noder = y_test[node_indicatorM[:,index_cr]==1]    
            
            if (np.isnan(np.mean(y_test_nodel)) | np.isnan(np.mean(y_test_noder))) :
                tree.tree_.children_left[j] = -1
                tree.tree_.children_right[j] = -1
            # if np.isnan(np.mean(y_test_nodel)) : print('index of node that should get pruned: left',index_cl)
            # if np.isnan(np.mean(y_test_noder)) : print('index of node that should get pruned: right',index_cr)

    return(tree)
    
def ReplaceRegTreeMSE(tree_orig,X_test,y_test):
    from sklearn import metrics
    tree = copy.deepcopy(tree_orig)
    node_indicatorM = tree.decision_path(X_test).toarray() 
    
    for j in range(len(tree.tree_.value)): # for each node, recalculate MSE (i.e. impurity)
        if tree.tree_.n_node_samples[j]!=0:
            # we want to indicate for each node, which sample are used
            y_test_true = y_test[node_indicatorM[:,j]==1]
            
            if len(y_test_true) !=0:
                y_test_pred = np.repeat(tree.tree_.value[j][0],len(y_test_true))
            
                mse = metrics.mean_squared_error(y_test_true,y_test_pred)
                tree.tree_.impurity[j] = mse
            else: tree.tree_.impurity[j] = np.nan
                
        else: 
            tree.tree_.impurity[j] = np.nan  
    return(tree)
    
```


### compute tree_B2 and tree_B3 for every tree in the random forest
And meanwhile compute shap values for oob data 
qi: issue: invalid value encountered in true_divide that we always ignored 
```{python}
import copy
n_samples, p = X_train.shape
rerun = True
if (rerun):
    explainer_rf = shap.TreeExplainer(rf)
    shapGlobal = explainer_rf.shap_values(X_train)
    
    shap_oob   = np.zeros((n_samples,p, rf.n_estimators))
    shap_oob2  = np.zeros((n_samples,p, rf.n_estimators))
    shap_oob3  = np.zeros((n_samples,p, rf.n_estimators))
    shap_inbag = np.zeros((n_samples,p, rf.n_estimators))
    for k,tree in enumerate(rf.estimators_):
        tree_preds = tree.predict(X_train) # qi: question: what is the use of this variable?
        unsampled_indices = generate_unsampled_indices(tree.random_state, n_samples)
        sampled_indices = generate_sample_indices(tree.random_state, n_samples)
        
        tree_B2 = ReplaceRegTreeNodeValues(tree,X_train.iloc[unsampled_indices,:],
                                              Y_train.iloc[unsampled_indices])
        tree_B3 = ReplaceRegTreeMSE(tree_B2,X_train.iloc[unsampled_indices,:]
                                         ,Y_train.iloc[unsampled_indices])
        
        explainer = shap.TreeExplainer(tree)
        explainer2 = shap.TreeExplainer(tree_B2)
        explainer3 = shap.TreeExplainer(tree_B3)
      
        shap_oob [unsampled_indices,:,k] = explainer.shap_values(X_train.iloc[unsampled_indices,:])
        shap_oob2[unsampled_indices,:,k] = explainer2.shap_values(X_train.iloc[unsampled_indices,:])
        shap_oob3[unsampled_indices,:,k] = explainer3.shap_values(X_train.iloc[unsampled_indices,:])
        shap_inbag[sampled_indices,:,k] = explainer.shap_values(X_train.iloc[sampled_indices,:])
    
explainer.shap_values(X_train.iloc[unsampled_indices,:]).shape
unsampled_indices.shape
X_train.iloc[unsampled_indices,:].shape
```


```{python}
shap_oob_avg = np.mean(shap_oob, axis=2) # qi: remark: take sum would do the same work
shap_oob2_avg = np.sum(shap_oob2, axis=2)
shap_oob3_avg = np.mean(shap_oob3, axis=2)
shap_inbag_avg = np.sum(shap_inbag, axis=2)

globalSHAPImp_oob =np.sum(np.abs(shap_oob_avg), axis=0)
globalSHAPImp_inbag = np.sum(np.abs(shap_inbag_avg), axis=0)

shap_test = explainer.shap_values(X_test)
```

### Copying python objects into R 

```{r, eval = rerun}
shap_inbag_avg =py$shap_inbag_avg 
shap_oob_avg =py$shap_oob_avg 
shap_oob2_avg =py$shap_oob2_avg
shap_oob3_avg =py$shap_oob3_avg
colnames(shap_inbag_avg) = colnames(shap_oob_avg) = colnames(shap_oob2_avg) = colnames(shap_oob3_avg)= c('Age', 'Pclass','Sex', 'PassengerId')
shap_test = py$shap_test

Y_train = py$Y_train
X_train = py$X_train
X_test = py$X_test
Y_test = py$Y_test
# qi: remark: careful overwritting here
# save(shap_inbag_avg, shap_oob_avg, shap_test, X_train, X_test, Y_train, Y_test, file = "shap_inbag_oob.rda")
```

# R code only

```{r}
shap_inbag_avg_means = colMeans(abs(shap_inbag_avg))# qi: note: same as np.mean(shap_inbag_avg,axis=0)
shap_oob_avg_means = colMeans(abs(shap_oob_avg))
shap_oob2_avg_means = colMeans(abs(shap_oob2_avg))
shap_oob3_avg_means = colMeans(abs(shap_oob3_avg))
```

## "Raw" SHAP values

```{r, fig.width=WIDTH*2,fig.height=HEIGHT*2}
par(mfrow=c(4,2))
boxplot(shap_inbag_avg,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Inbag SHAP");grid()
barplot(shap_inbag_avg_means,col="bisque",main = "Inbag SHAP")
boxplot(shap_oob_avg,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob_avg_means,col="bisque",main = "OOB SHAP B1")
boxplot(shap_oob2_avg,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob2_avg_means,col="bisque",main = "OOB SHAP B2")
boxplot(shap_oob3_avg,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob3_avg_means,col="bisque",main = "OOB SHAP B3")
# means = colMeans(mdiScore2[[4]]);points(means,col="red",pch=18)

```

# R code only

```{r}
Y_test2 = Y_test
Y_test2[Y_test2==0] = -1
Y_train2 = Y_train
Y_train2[Y_train==0] = -1
```

## Weighting by Y 

```{r}
shap_inbag_wght = shap_inbag_avg
shap_oob_wght = shap_oob2_wght = shap_oob3_wght = shap_oob_avg

for (i in 1:4) {
  shap_inbag_wght[,i] = Y_train*shap_inbag_avg[,i]
  shap_oob_wght[,i]   = Y_train*shap_oob_avg[,i]
  shap_oob2_wght[,i]  = Y_train*shap_oob2_avg[,i]
  shap_oob2_wght[,i]  = Y_train*shap_oob3_avg[,i]
}

shap_inbag_wght_means = colMeans(abs(shap_inbag_wght))
shap_oob_wght_means   = colMeans(abs(shap_oob_wght))
shap_oob2_wght_means  = colMeans(abs(shap_oob2_wght))
shap_oob3_wght_means  = colMeans(abs(shap_oob3_wght))
```

```{r, fig.width=WIDTH*2,fig.height=HEIGHT*2}
par(mfrow=c(4,2))
boxplot(shap_inbag_wght,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Inbag SHAP");grid()
barplot(shap_inbag_wght_means,col="bisque",main = "Inbag SHAP")

boxplot(shap_oob_wght,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob_wght_means,col="bisque",main = "OOB SHAP")
boxplot(shap_oob2_wght,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob2_wght_means,col="bisque",main = "OOB2 SHAP")
boxplot(shap_oob3_wght,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob3_wght_means,col="bisque",main = "OOB3 SHAP")
```

## Weighting by Y2 

qi: open question: 
Whether we code the output as $(0,1)$ or as $(-1, 1)$ makes no difference?

```{r}
shap_inbag_wght = shap_inbag_avg
shap_oob_wght = shap_oob2_wght=shap_oob3_wght=shap_oob_avg

for (i in 1:4) {
  shap_inbag_wght[,i] = Y_train2*shap_inbag_avg[,i]
  shap_oob_wght[,i]   = Y_train2*shap_oob_avg[,i]
  shap_oob2_wght[,i]  = Y_train2*shap_oob2_avg[,i]
  shap_oob3_wght[,i]  = Y_train2*shap_oob3_avg[,i]
}

shap_inbag_wght_means = colMeans(abs(shap_inbag_wght))
shap_oob_wght_means   = colMeans(abs(shap_oob_wght))
shap_oob2_wght_means  = colMeans(abs(shap_oob2_wght))
shap_oob3_wght_means  = colMeans(abs(shap_oob3_wght))
```

```{r, fig.width=WIDTH*2,fig.height=HEIGHT*2}
par(mfrow=c(4,2))
boxplot(shap_inbag_wght,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Inbag SHAP");grid()
barplot(shap_inbag_wght_means,col="bisque",main = "Inbag SHAP")

boxplot(shap_oob_wght,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob_wght_means,col="bisque",main = "OOB SHAP")
boxplot(shap_oob2_wght,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob2_wght_means,col="bisque",main = "OOB2 SHAP")
boxplot(shap_oob3_wght,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob3_wght_means,col="bisque",main = "OOB3 SHAP")

```

# Motivation

Why multiply by Y ? 

I believe that ultimately the misleading feature importances are an overfitting problem
The global importance scores are averages of the **absolute values** of the SHAP values, so they reflect merely variation; regardless whether that variation reflects the truth at all. # qi: note :variation of what?

So for e.g. passengerID the model will still produce widely varying SHAP values even on a testset (or oob) -leading to inflated importance - but we would want to "penalize" the wrong direction! # qi: note: which is the wrong direction?
(Not possible on the training data as the model was fit in order to optimize the agreement with $Y_{train}$).

## Inbag versus Outbag

For the inbag data we observe a strong correlation between the sign of the SHAP vales and the sign of $Y_{train}$, whereas this correlation disappears almost entirely for those features that suffer from overfitting (such as passenger ID): 

```{r, fig.width=WIDTH*2,fig.height=HEIGHT*2}
library(ggplot2)
N = nrow(shap_inbag_avg) # qi: same as N=length(Y_train)
N2 = nrow(shap_test)
shap = list()

#sigh,yes, I know, what a clumsy way to create a long data frame!
for (j in 1:4){
  shap[[j]] = cbind.data.frame(shap=c(shap_inbag_avg[,j], 
                                      oob = shap_oob_avg[,j],
                                      oob2 = shap_oob2_avg[,j],
                                      oob3 = shap_oob3_avg[,j]), 
                                
                               bag = rep(c("inbag","oob",'oob2','oob3'), each=N), 
                               Y_train2=factor(c(Y_train2,Y_train2,Y_train2,Y_train2)))
# qi: open question: the problem of scale, and comparability 
tmp = cbind.data.frame(shap=20*shap_test[,j], bag = rep("test", each=N2), Y_train2=factor(Y_test2))
  shap[[j]] = rbind.data.frame(shap[[j]], tmp)

}
shap = do.call("rbind.data.frame", shap)
shap$feature = rep(colnames(shap_inbag_avg), each =4*N+N2)

  
ggplot(shap, aes(x=Y_train2, y=shap, fill=bag)) + geom_boxplot() + facet_wrap(~ feature)

```

```{r}
shap[c(1:10),]
```

## inbag-outbag correlations

qi: note:is it necessary to check the correlation between oob2&3 with inbag respectively?

For new data, multiplying by Y will not be feasible anyhow, so we need to look for other ways of correcting the SHAP values.

MSE or some other measure of goodness of fit could be used as an indicator for the reliability of the importance measures. 

```{r,echo=FALSE}
save(shap,shap_inbag_avg,shap_oob3_avg,shap_oob2_avg,shap_oob_avg, file = "SHAP_bias/data/shap_SHAP_TitanicRegV3.rda")
```


```{r, fig.width=WIDTH,fig.height=HEIGHT}
par(mfrow=c(2,2))
for (j in 1:4){
  fit = lm(shap_oob_avg[,j] ~ shap_inbag_avg[,j])
  R2 = round(summary(fit)$r.sq,2)
  
  plot(shap_inbag_avg[,j],shap_oob_avg[,j],col=rgb(0,0,1,0.5), pch=20,cex=0.75, xlab = "Inbag SHAP", ylab="oob shap", main = paste0(colnames(shap_inbag_avg)[j], " (R2 =", R2,")"));grid()
  
  abline(fit,col=2)
}
```

```{r, fig.width=WIDTH,fig.height=HEIGHT}
par(mfrow=c(2,2))
for (j in 1:4){
  fit = lm(shap_oob2_avg[,j] ~ shap_inbag_avg[,j])
  R2 = round(summary(fit)$r.sq,2)
  
  plot(shap_inbag_avg[,j],shap_oob2_avg[,j],col=rgb(0,0,1,0.5), pch=20,cex=0.75, xlab = "Inbag SHAP", ylab="oob2 shap", main = paste0(colnames(shap_inbag_avg)[j], " (R2 =", R2,")"));grid()
  
  abline(fit,col=2)
}
```

```{r, fig.width=WIDTH,fig.height=HEIGHT}
par(mfrow=c(2,2))
for (j in 1:4){
  fit = lm(shap_oob3_avg[,j] ~ shap_inbag_avg[,j])
  R2 = round(summary(fit)$r.sq,2)
  
  plot(shap_inbag_avg[,j],shap_oob3_avg[,j],col=rgb(0,0,1,0.5), pch=20,cex=0.75, xlab = "Inbag SHAP", ylab="oob3 shap", main = paste0(colnames(shap_inbag_avg)[j], " (R2 =", R2,")"));grid()
  
  abline(fit,col=2)
}
```