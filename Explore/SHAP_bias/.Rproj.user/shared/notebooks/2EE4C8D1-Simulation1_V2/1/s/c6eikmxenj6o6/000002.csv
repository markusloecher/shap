"0","#https://github.com/parrt/random-forest-importances/blob/master/src/rfpimp.py
def oob_regression_r2_score(rf, X_train, y_train): # qi: note: this function is not used yet
    """"""
    Compute out-of-bag (OOB) R^2 for a scikit-learn random forest
    regressor. We learned the guts of scikit's RF from the BSD licensed
    code:
    https://github.com/scikit-learn/scikit-learn/blob/a24c8b46/sklearn/ensemble/forest.py#L702
    """"""
    from sklearn.metrics import r2_score
    X = X_train.values if isinstance(X_train, pd.DataFrame) else X_train
    y = y_train.values if isinstance(y_train, pd.Series) else y_train

    n_samples = len(X)
    predictions = np.zeros(n_samples)
    n_predictions = np.zeros(n_samples)
    for tree in rf.estimators_:
        unsampled_indices = generate_unsampled_indices(tree.random_state, n_samples)
        tree_preds = tree.predict(X[unsampled_indices, :])
        predictions[unsampled_indices] += tree_preds
        n_predictions[unsampled_indices] += 1

    if (n_predictions == 0).any():
        warnings.warn(""Too few trees; some variables do not have OOB scores."")
        n_predictions[n_predictions == 0] = 1

    predictions /= n_predictions

    oob_score = r2_score(y, predictions)
    return oob_score

#http://bakfu.github.io/doc/_modules/sklearn/ensemble/forest.html
from sklearn.utils import check_random_state #, check_array, compute_sample_weight
#from sklearn.utils.fixes import bincount

def generate_sample_indices(random_state, n_samples):
    """"""Private function used to _parallel_build_trees function.""""""
    random_instance = check_random_state(random_state)
    sample_indices = random_instance.randint(0, n_samples, n_samples)

    return sample_indices

def generate_unsampled_indices(random_state, n_samples):
    """"""Private function used to forest._set_oob_score fuction.""""""
    sample_indices = generate_sample_indices(random_state, n_samples)
    sample_counts = np.bincount(sample_indices, minlength=n_samples)
    unsampled_mask = sample_counts == 0
    indices_range = np.arange(n_samples)
    unsampled_indices = indices_range[unsampled_mask]

    return unsampled_indices

def shap_values_oob(X_train, rf):
    n_samples, p = X_train.shape
    shap_oob = np.zeros((n_samples, p, rf.n_estimators))
    shap_inbag = np.zeros((n_samples, p, rf.n_estimators))
    for k,tree in enumerate(rf.estimators_):
      tree_preds = tree.predict(X_train)
      unsampled_indices = generate_unsampled_indices(tree.random_state, n_samples)
      sampled_indices = generate_sample_indices(tree.random_state, n_samples)
      explainer = shap.TreeExplainer(tree)
      shap_oob[unsampled_indices,:,k] = explainer.shap_values(X_train.iloc[unsampled_indices,:])
      shap_inbag[sampled_indices,:,k] = explainer.shap_values(X_train.iloc[sampled_indices,:])
    
    shap_oob_avg = np.mean(shap_oob, axis=2) # average the value for rf.n_estimators numbers of trees
    shap_inbag_avg = np.mean(shap_inbag, axis=2)
    globalSHAPImp_oob =np.mean(np.abs(shap_oob_avg), axis=0)# average the shap value for every observation
    globalSHAPImp_inbag = np.mean(np.abs(shap_inbag_avg), axis=0)
    return shap_oob,shap_inbag,shap_oob_avg,shap_inbag_avg,globalSHAPImp_oob,globalSHAPImp_inbag"
