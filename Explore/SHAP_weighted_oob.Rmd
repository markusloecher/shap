---
title: "SHAP values for inbag vs. oob data"
author: "M Loecher"
date: "25 11 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
#py_install("shap")
```


```{python}
import pandas as pd
import numpy as np
np.random.seed(0)
import matplotlib.pyplot as plt
import shap
import pickle

from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.ensemble import RandomForestRegressor

rerun = True
```


## Setting up the data 

```{python}
df = pd.read_csv('https://raw.githubusercontent.com/markusloecher/shap/master/Explore/titanicnoMissingAge.csv') # Load the data
#df
Y = df['Survived']
X =  df[['Age', 'Pclass','Sex', 'PassengerId']]
# Split the data into train and test data:
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)
```

## Defining our functions

```{python}
def plotImp(importances,features, main = 'Feature Importances',xlab='Relative Importance'):
    indices = np.argsort(importances)
    #features = X_train.columns
    plt.title(main)
    plt.barh(range(len(indices)), importances[indices], color='b', align='center')
    plt.yticks(range(len(indices)), [features[i] for i in indices])
    plt.xlabel(xlab)
    plt.show()
    
def oob_regression_r2_score(rf, X_train, y_train):
    """
    Compute out-of-bag (OOB) R^2 for a scikit-learn random forest
    regressor. We learned the guts of scikit's RF from the BSD licensed
    code:
    https://github.com/scikit-learn/scikit-learn/blob/a24c8b46/sklearn/ensemble/forest.py#L702
    """
    X = X_train.values if isinstance(X_train, pd.DataFrame) else X_train
    y = y_train.values if isinstance(y_train, pd.Series) else y_train

    n_samples = len(X)
    predictions = np.zeros(n_samples)
    n_predictions = np.zeros(n_samples)
    for tree in rf.estimators_:
        unsampled_indices = generate_unsampled_indices(tree.random_state, n_samples)
        tree_preds = tree.predict(X[unsampled_indices, :])
        predictions[unsampled_indices] += tree_preds
        n_predictions[unsampled_indices] += 1

    if (n_predictions == 0).any():
        warnings.warn("Too few trees; some variables do not have OOB scores.")
        n_predictions[n_predictions == 0] = 1

    predictions /= n_predictions

    oob_score = r2_score(y, predictions)
    return oob_score

#http://bakfu.github.io/doc/_modules/sklearn/ensemble/forest.html
from sklearn.utils import check_random_state #, check_array, compute_sample_weight
#from sklearn.utils.fixes import bincount

def generate_sample_indices(random_state, n_samples):
    """Private function used to _parallel_build_trees function."""
    random_instance = check_random_state(random_state)
    sample_indices = random_instance.randint(0, n_samples, n_samples)

    return sample_indices

def generate_unsampled_indices(random_state, n_samples):
    """Private function used to forest._set_oob_score fuction."""
    sample_indices = generate_sample_indices(random_state, n_samples)
    sample_counts = np.bincount(sample_indices, minlength=n_samples)
    unsampled_mask = sample_counts == 0
    indices_range = np.arange(n_samples)
    unsampled_indices = indices_range[unsampled_mask]

    return unsampled_indices
```


## Fitting a random forest

```{python}
rf = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=100,max_features=2)
rf.fit(X_train, Y_train)  
print(rf.feature_importances_)
importances = rf.feature_importances_
features = X_train.columns

plotImp(importances,features)
```

## Computing shap separately for inbag and oob:

```{python}
n_samples, p = X_train.shape

if (rerun):
    explainer = shap.TreeExplainer(rf)
    shapGlobal = explainer.shap_values(X_train)

    k=0
    shap_oob = np.zeros((n_samples,p, rf.n_estimators))
    shap_inbag = np.zeros((n_samples,p, rf.n_estimators))
    for tree in rf.estimators_:
      tree_preds = tree.predict(X_train)
      unsampled_indices = generate_unsampled_indices(tree.random_state, n_samples)
      sampled_indices = generate_sample_indices(tree.random_state, n_samples)
      explainer = shap.TreeExplainer(tree)
      shap_oob[unsampled_indices,:,k] = explainer.shap_values(X_train.iloc[unsampled_indices,:])
      shap_inbag[sampled_indices,:,k] = explainer.shap_values(X_train.iloc[sampled_indices,:])
      #print(k)
      k+=1
```

```{python}
shap_oob_avg = np.sum(shap_oob, axis=2) 
shap_inbag_avg = np.sum(shap_inbag, axis=2)

globalSHAPImp_oob =np.sum(np.abs(shap_oob_avg), axis=0)
globalSHAPImp_inbag = np.sum(np.abs(shap_inbag_avg), axis=0)
```

```{r}
shap_inbag_avg =py$shap_inbag_avg 
shap_oob_avg =py$shap_oob_avg 
colnames(shap_inbag_avg) = colnames(shap_oob_avg) = c('Age', 'Pclass','Sex', 'PassengerId')

Y_train = py$Y_train
Y_train2 = Y_train
Y_train2[Y_train==0] = -1
shap_inbag_avg_means = colMeans(abs(shap_inbag_avg))
shap_oob_avg_means = colMeans(abs(shap_oob_avg))
```

## "Raw" SHAP values

```{r, fig.width=10,fig.height=6}
par(mfrow=c(2,2))
boxplot(shap_inbag_avg,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Inbag SHAP");grid()
barplot(shap_inbag_avg_means,col="bisque",main = "Inbag SHAP")
boxplot(shap_oob_avg,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob_avg_means,col="bisque",main = "OOB SHAP")
#means = colMeans(mdiScore2[[4]]);points(means,col="red",pch=18)

```

## Weighting by Y 

```{r}
shap_inbag_wght = shap_inbag_avg
shap_oob_wght = shap_oob_avg

for (i in 1:4) {
  shap_inbag_wght[,i] = Y_train*shap_inbag_avg[,i]
  shap_oob_wght[,i] = Y_train*shap_oob_avg[,i]
}

shap_inbag_wght_means = colMeans(shap_inbag_wght)
shap_oob_wght_means = colMeans(shap_oob_wght)
```

```{r, fig.width=10,fig.height=6}
par(mfrow=c(2,2))
boxplot(shap_inbag_wght,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Inbag SHAP");grid()
barplot(shap_inbag_wght_means,col="bisque",main = "Inbag SHAP")
boxplot(shap_oob_wght,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob_wght_means,col="bisque",main = "OOB SHAP")

```

## Weighting by Y2 

```{r}
shap_inbag_wght = shap_inbag_avg
shap_oob_wght = shap_oob_avg

for (i in 1:4) {
  shap_inbag_wght[,i] = Y_train2*shap_inbag_avg[,i]
  shap_oob_wght[,i] = Y_train2*shap_oob_avg[,i]
}

shap_inbag_wght_means = colMeans(shap_inbag_wght)
shap_oob_wght_means = colMeans(shap_oob_wght)
```

```{r, fig.width=10,fig.height=6}
par(mfrow=c(2,2))
boxplot(shap_inbag_wght,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Inbag SHAP");grid()
barplot(shap_inbag_wght_means,col="bisque",main = "Inbag SHAP")
boxplot(shap_oob_wght,col=rgb(0,0,1,0.5), outcol=rgb(0,0,1,0.5),pch=20,cex=0.75, ylab = "Outbag SHAP");grid()
barplot(shap_oob_wght_means,col="bisque",main = "OOB SHAP")

```
